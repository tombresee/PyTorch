{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "tensor_tutorialv2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tombresee/PyTorch/blob/main/ENTER/notebooks/tensor_tutorialv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfqjw9yCOAMP"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbdzkaWcOAMS"
      },
      "source": [
        "\n",
        "What is PyTorch?\n",
        "================\n",
        "\n",
        "It’s a Python-based scientific computing package targeted at two sets of\n",
        "audiences:\n",
        "\n",
        "-  A replacement for NumPy to use the power of GPUs\n",
        "-  a deep learning research platform that provides maximum flexibility\n",
        "   and speed\n",
        "\n",
        "Getting Started\n",
        "---------------\n",
        "\n",
        "Tensors\n",
        "^^^^^^^\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that\n",
        "Tensors can also be used on a GPU to accelerate computing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUPXjFYWOAMS"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LEobTCyBgJe",
        "outputId": "78b2269e-61f0-4499-ed21-3178379f7cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dir(torch)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AVG',\n",
              " 'AggregationType',\n",
              " 'AnyType',\n",
              " 'Argument',\n",
              " 'ArgumentSpec',\n",
              " 'BFloat16Storage',\n",
              " 'BFloat16Tensor',\n",
              " 'BenchmarkConfig',\n",
              " 'BenchmarkExecutionStats',\n",
              " 'Block',\n",
              " 'BoolStorage',\n",
              " 'BoolTensor',\n",
              " 'BoolType',\n",
              " 'BufferDict',\n",
              " 'ByteStorage',\n",
              " 'ByteTensor',\n",
              " 'CONV_BN_FUSION',\n",
              " 'CallStack',\n",
              " 'Capsule',\n",
              " 'CharStorage',\n",
              " 'CharTensor',\n",
              " 'ClassType',\n",
              " 'Code',\n",
              " 'CompilationUnit',\n",
              " 'CompleteArgumentSpec',\n",
              " 'ComplexDoubleStorage',\n",
              " 'ComplexFloatStorage',\n",
              " 'ConcreteModuleType',\n",
              " 'ConcreteModuleTypeBuilder',\n",
              " 'CudaBFloat16StorageBase',\n",
              " 'CudaBoolStorageBase',\n",
              " 'CudaByteStorageBase',\n",
              " 'CudaCharStorageBase',\n",
              " 'CudaComplexDoubleStorageBase',\n",
              " 'CudaComplexFloatStorageBase',\n",
              " 'CudaDoubleStorageBase',\n",
              " 'CudaFloatStorageBase',\n",
              " 'CudaHalfStorageBase',\n",
              " 'CudaIntStorageBase',\n",
              " 'CudaLongStorageBase',\n",
              " 'CudaShortStorageBase',\n",
              " 'DeepCopyMemoTable',\n",
              " 'DeviceObjType',\n",
              " 'DictType',\n",
              " 'DoubleStorage',\n",
              " 'DoubleTensor',\n",
              " 'ErrorReport',\n",
              " 'ExecutionPlan',\n",
              " 'ExtraFilesMap',\n",
              " 'FatalError',\n",
              " 'FileCheck',\n",
              " 'FloatStorage',\n",
              " 'FloatTensor',\n",
              " 'FloatType',\n",
              " 'FunctionSchema',\n",
              " 'Future',\n",
              " 'FutureType',\n",
              " 'Generator',\n",
              " 'Gradient',\n",
              " 'Graph',\n",
              " 'GraphExecutorState',\n",
              " 'HalfStorage',\n",
              " 'HalfStorageBase',\n",
              " 'HalfTensor',\n",
              " 'INSERT_FOLD_PREPACK_OPS',\n",
              " 'IODescriptor',\n",
              " 'IntStorage',\n",
              " 'IntTensor',\n",
              " 'IntType',\n",
              " 'InterfaceType',\n",
              " 'JITException',\n",
              " 'ListType',\n",
              " 'LiteScriptModule',\n",
              " 'LockingLogger',\n",
              " 'LoggerBase',\n",
              " 'LongStorage',\n",
              " 'LongTensor',\n",
              " 'MobileOptimizerType',\n",
              " 'ModuleDict',\n",
              " 'Node',\n",
              " 'NoneType',\n",
              " 'NoopLogger',\n",
              " 'NumberType',\n",
              " 'OptionalType',\n",
              " 'ParameterDict',\n",
              " 'PyObjectType',\n",
              " 'PyTorchFileReader',\n",
              " 'PyTorchFileWriter',\n",
              " 'QInt32Storage',\n",
              " 'QInt32StorageBase',\n",
              " 'QInt8Storage',\n",
              " 'QInt8StorageBase',\n",
              " 'QUInt8Storage',\n",
              " 'REMOVE_DROPOUT',\n",
              " 'RRefType',\n",
              " 'SUM',\n",
              " 'ScriptClass',\n",
              " 'ScriptFunction',\n",
              " 'ScriptMethod',\n",
              " 'ScriptModule',\n",
              " 'ScriptObject',\n",
              " 'Set',\n",
              " 'ShortStorage',\n",
              " 'ShortTensor',\n",
              " 'Size',\n",
              " 'Storage',\n",
              " 'StringType',\n",
              " 'Tensor',\n",
              " 'TensorType',\n",
              " 'ThroughputBenchmark',\n",
              " 'TracingState',\n",
              " 'TupleType',\n",
              " 'Type',\n",
              " 'USE_GLOBAL_DEPS',\n",
              " 'USE_RTLD_GLOBAL_WITH_LIBTORCH',\n",
              " 'Use',\n",
              " 'Value',\n",
              " '_C',\n",
              " '_StorageBase',\n",
              " '_VF',\n",
              " '__all__',\n",
              " '__annotations__',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__config__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__future__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__version__',\n",
              " '_adaptive_avg_pool2d',\n",
              " '_addmv_impl_',\n",
              " '_addr',\n",
              " '_addr_',\n",
              " '_amp_non_finite_check_and_unscale_',\n",
              " '_amp_update_scale',\n",
              " '_baddbmm_mkl_',\n",
              " '_batch_norm_impl_index',\n",
              " '_bmm',\n",
              " '_cast_Byte',\n",
              " '_cast_Char',\n",
              " '_cast_Double',\n",
              " '_cast_Float',\n",
              " '_cast_Half',\n",
              " '_cast_Int',\n",
              " '_cast_Long',\n",
              " '_cast_Short',\n",
              " '_cat',\n",
              " '_choose_qparams_per_tensor',\n",
              " '_classes',\n",
              " '_convolution',\n",
              " '_convolution_nogroup',\n",
              " '_copy_from',\n",
              " '_ctc_loss',\n",
              " '_cudnn_ctc_loss',\n",
              " '_cudnn_init_dropout_state',\n",
              " '_cudnn_rnn',\n",
              " '_cudnn_rnn_flatten_weight',\n",
              " '_cufft_clear_plan_cache',\n",
              " '_cufft_get_plan_cache_max_size',\n",
              " '_cufft_get_plan_cache_size',\n",
              " '_cufft_set_plan_cache_max_size',\n",
              " '_cummax_helper',\n",
              " '_cummin_helper',\n",
              " '_debug_has_internal_overlap',\n",
              " '_dim_arange',\n",
              " '_dirichlet_grad',\n",
              " '_embedding_bag',\n",
              " '_empty_affine_quantized',\n",
              " '_empty_per_channel_affine_quantized',\n",
              " '_euclidean_dist',\n",
              " '_fft_with_size',\n",
              " '_fused_dropout',\n",
              " '_has_compatible_shallow_copy_type',\n",
              " '_import_dotted_name',\n",
              " '_index_copy_',\n",
              " '_index_put_impl_',\n",
              " '_is_deterministic',\n",
              " '_jit_internal',\n",
              " '_linalg_utils',\n",
              " '_load_global_deps',\n",
              " '_lobpcg',\n",
              " '_log_softmax',\n",
              " '_log_softmax_backward_data',\n",
              " '_logcumsumexp',\n",
              " '_lowrank',\n",
              " '_lu_solve_helper',\n",
              " '_lu_with_info',\n",
              " '_make_per_channel_quantized_tensor',\n",
              " '_make_per_tensor_quantized_tensor',\n",
              " '_masked_scale',\n",
              " '_mkldnn',\n",
              " '_mkldnn_reshape',\n",
              " '_mkldnn_transpose',\n",
              " '_mkldnn_transpose_',\n",
              " '_mode',\n",
              " '_multinomial_alias_draw',\n",
              " '_multinomial_alias_setup',\n",
              " '_namedtensor_internals',\n",
              " '_nnpack_available',\n",
              " '_nnpack_spatial_convolution',\n",
              " '_ops',\n",
              " '_overrides',\n",
              " '_pack_padded_sequence',\n",
              " '_pad_packed_sequence',\n",
              " '_reshape_from_tensor',\n",
              " '_s_where',\n",
              " '_sample_dirichlet',\n",
              " '_set_deterministic',\n",
              " '_shape_as_tensor',\n",
              " '_six',\n",
              " '_sobol_engine_draw',\n",
              " '_sobol_engine_ff_',\n",
              " '_sobol_engine_initialize_state_',\n",
              " '_sobol_engine_scramble_',\n",
              " '_softmax',\n",
              " '_softmax_backward_data',\n",
              " '_sparse_addmm',\n",
              " '_sparse_log_softmax',\n",
              " '_sparse_log_softmax_backward_data',\n",
              " '_sparse_mm',\n",
              " '_sparse_softmax',\n",
              " '_sparse_softmax_backward_data',\n",
              " '_sparse_sum',\n",
              " '_standard_gamma',\n",
              " '_standard_gamma_grad',\n",
              " '_storage_classes',\n",
              " '_string_classes',\n",
              " '_tensor_classes',\n",
              " '_tensor_str',\n",
              " '_test_serialization_subcmul',\n",
              " '_trilinear',\n",
              " '_unique',\n",
              " '_unique2',\n",
              " '_use_cudnn_ctc_loss',\n",
              " '_use_cudnn_rnn_flatten_weight',\n",
              " '_utils',\n",
              " '_utils_internal',\n",
              " '_weight_norm',\n",
              " '_weight_norm_cuda_interface',\n",
              " 'abs',\n",
              " 'abs_',\n",
              " 'absolute',\n",
              " 'absolute_',\n",
              " 'acos',\n",
              " 'acos_',\n",
              " 'acosh',\n",
              " 'acosh_',\n",
              " 'adaptive_avg_pool1d',\n",
              " 'adaptive_max_pool1d',\n",
              " 'add',\n",
              " 'addbmm',\n",
              " 'addcdiv',\n",
              " 'addcmul',\n",
              " 'addmm',\n",
              " 'addmv',\n",
              " 'addmv_',\n",
              " 'addr',\n",
              " 'affine_grid_generator',\n",
              " 'align_tensors',\n",
              " 'all',\n",
              " 'allclose',\n",
              " 'alpha_dropout',\n",
              " 'alpha_dropout_',\n",
              " 'angle',\n",
              " 'any',\n",
              " 'arange',\n",
              " 'argmax',\n",
              " 'argmin',\n",
              " 'argsort',\n",
              " 'as_strided',\n",
              " 'as_strided_',\n",
              " 'as_tensor',\n",
              " 'asin',\n",
              " 'asin_',\n",
              " 'asinh',\n",
              " 'asinh_',\n",
              " 'atan',\n",
              " 'atan2',\n",
              " 'atan_',\n",
              " 'atanh',\n",
              " 'atanh_',\n",
              " 'autocast_decrement_nesting',\n",
              " 'autocast_increment_nesting',\n",
              " 'autograd',\n",
              " 'avg_pool1d',\n",
              " 'backends',\n",
              " 'baddbmm',\n",
              " 'bartlett_window',\n",
              " 'batch_norm',\n",
              " 'batch_norm_backward_elemt',\n",
              " 'batch_norm_backward_reduce',\n",
              " 'batch_norm_elemt',\n",
              " 'batch_norm_gather_stats',\n",
              " 'batch_norm_gather_stats_with_counts',\n",
              " 'batch_norm_stats',\n",
              " 'batch_norm_update_stats',\n",
              " 'bernoulli',\n",
              " 'bfloat16',\n",
              " 'bilinear',\n",
              " 'binary_cross_entropy_with_logits',\n",
              " 'bincount',\n",
              " 'binomial',\n",
              " 'bitwise_and',\n",
              " 'bitwise_not',\n",
              " 'bitwise_or',\n",
              " 'bitwise_xor',\n",
              " 'blackman_window',\n",
              " 'block_diag',\n",
              " 'bmm',\n",
              " 'bool',\n",
              " 'broadcast_tensors',\n",
              " 'bucketize',\n",
              " 'can_cast',\n",
              " 'cartesian_prod',\n",
              " 'cat',\n",
              " 'cdist',\n",
              " 'cdouble',\n",
              " 'ceil',\n",
              " 'ceil_',\n",
              " 'celu',\n",
              " 'celu_',\n",
              " 'cfloat',\n",
              " 'chain_matmul',\n",
              " 'channel_shuffle',\n",
              " 'channels_last',\n",
              " 'channels_last_3d',\n",
              " 'cholesky',\n",
              " 'cholesky_inverse',\n",
              " 'cholesky_solve',\n",
              " 'chunk',\n",
              " 'clamp',\n",
              " 'clamp_',\n",
              " 'clamp_max',\n",
              " 'clamp_max_',\n",
              " 'clamp_min',\n",
              " 'clamp_min_',\n",
              " 'classes',\n",
              " 'clear_autocast_cache',\n",
              " 'clone',\n",
              " 'combinations',\n",
              " 'compiled_with_cxx11_abi',\n",
              " 'complex128',\n",
              " 'complex32',\n",
              " 'complex64',\n",
              " 'conj',\n",
              " 'constant_pad_nd',\n",
              " 'contiguous_format',\n",
              " 'conv1d',\n",
              " 'conv2d',\n",
              " 'conv3d',\n",
              " 'conv_tbc',\n",
              " 'conv_transpose1d',\n",
              " 'conv_transpose2d',\n",
              " 'conv_transpose3d',\n",
              " 'convolution',\n",
              " 'cos',\n",
              " 'cos_',\n",
              " 'cosh',\n",
              " 'cosh_',\n",
              " 'cosine_embedding_loss',\n",
              " 'cosine_similarity',\n",
              " 'cpp',\n",
              " 'cross',\n",
              " 'ctc_loss',\n",
              " 'ctypes',\n",
              " 'cuda',\n",
              " 'cudnn_affine_grid_generator',\n",
              " 'cudnn_batch_norm',\n",
              " 'cudnn_convolution',\n",
              " 'cudnn_convolution_transpose',\n",
              " 'cudnn_grid_sampler',\n",
              " 'cudnn_is_acceptable',\n",
              " 'cummax',\n",
              " 'cummin',\n",
              " 'cumprod',\n",
              " 'cumsum',\n",
              " 'default_generator',\n",
              " 'deg2rad',\n",
              " 'deg2rad_',\n",
              " 'dequantize',\n",
              " 'det',\n",
              " 'detach',\n",
              " 'detach_',\n",
              " 'device',\n",
              " 'diag',\n",
              " 'diag_embed',\n",
              " 'diagflat',\n",
              " 'diagonal',\n",
              " 'digamma',\n",
              " 'dist',\n",
              " 'distributed',\n",
              " 'distributions',\n",
              " 'div',\n",
              " 'dot',\n",
              " 'double',\n",
              " 'dropout',\n",
              " 'dropout_',\n",
              " 'dsmm',\n",
              " 'dtype',\n",
              " 'eig',\n",
              " 'einsum',\n",
              " 'embedding',\n",
              " 'embedding_bag',\n",
              " 'embedding_renorm_',\n",
              " 'empty',\n",
              " 'empty_like',\n",
              " 'empty_meta',\n",
              " 'empty_quantized',\n",
              " 'empty_strided',\n",
              " 'enable_grad',\n",
              " 'eq',\n",
              " 'equal',\n",
              " 'erf',\n",
              " 'erf_',\n",
              " 'erfc',\n",
              " 'erfc_',\n",
              " 'erfinv',\n",
              " 'exp',\n",
              " 'exp_',\n",
              " 'expm1',\n",
              " 'expm1_',\n",
              " 'eye',\n",
              " 'fake_quantize_per_channel_affine',\n",
              " 'fake_quantize_per_tensor_affine',\n",
              " 'fbgemm_linear_fp16_weight',\n",
              " 'fbgemm_linear_fp16_weight_fp32_activation',\n",
              " 'fbgemm_linear_int8_weight',\n",
              " 'fbgemm_linear_int8_weight_fp32_activation',\n",
              " 'fbgemm_linear_quantize_weight',\n",
              " 'fbgemm_pack_gemm_matrix_fp16',\n",
              " 'fbgemm_pack_quantized_matrix',\n",
              " 'feature_alpha_dropout',\n",
              " 'feature_alpha_dropout_',\n",
              " 'feature_dropout',\n",
              " 'feature_dropout_',\n",
              " 'fft',\n",
              " 'fill_',\n",
              " 'finfo',\n",
              " 'flatten',\n",
              " 'flip',\n",
              " 'fliplr',\n",
              " 'flipud',\n",
              " 'float',\n",
              " 'float16',\n",
              " 'float32',\n",
              " 'float64',\n",
              " 'floor',\n",
              " 'floor_',\n",
              " 'floor_divide',\n",
              " 'fmod',\n",
              " 'fork',\n",
              " 'frac',\n",
              " 'frac_',\n",
              " 'frobenius_norm',\n",
              " 'from_file',\n",
              " 'from_numpy',\n",
              " 'full',\n",
              " 'full_like',\n",
              " 'functional',\n",
              " 'futures',\n",
              " 'gather',\n",
              " 'ge',\n",
              " 'geqrf',\n",
              " 'ger',\n",
              " 'get_default_dtype',\n",
              " 'get_device',\n",
              " 'get_file_path',\n",
              " 'get_num_interop_threads',\n",
              " 'get_num_threads',\n",
              " 'get_rng_state',\n",
              " 'grid_sampler',\n",
              " 'grid_sampler_2d',\n",
              " 'grid_sampler_3d',\n",
              " 'group_norm',\n",
              " 'gru',\n",
              " 'gru_cell',\n",
              " 'gt',\n",
              " 'half',\n",
              " 'hamming_window',\n",
              " 'hann_window',\n",
              " 'hardshrink',\n",
              " 'has_cuda',\n",
              " 'has_cudnn',\n",
              " 'has_lapack',\n",
              " 'has_mkl',\n",
              " 'has_mkldnn',\n",
              " 'has_openmp',\n",
              " 'hinge_embedding_loss',\n",
              " 'histc',\n",
              " 'hsmm',\n",
              " 'hspmm',\n",
              " 'hub',\n",
              " 'ifft',\n",
              " 'iinfo',\n",
              " 'imag',\n",
              " 'import_ir_module',\n",
              " 'import_ir_module_from_buffer',\n",
              " 'index_add',\n",
              " 'index_copy',\n",
              " 'index_fill',\n",
              " 'index_put',\n",
              " 'index_put_',\n",
              " 'index_select',\n",
              " 'init_num_threads',\n",
              " 'initial_seed',\n",
              " 'instance_norm',\n",
              " 'int',\n",
              " 'int16',\n",
              " 'int32',\n",
              " 'int64',\n",
              " 'int8',\n",
              " 'int_repr',\n",
              " 'inverse',\n",
              " 'irfft',\n",
              " 'is_anomaly_enabled',\n",
              " 'is_autocast_enabled',\n",
              " 'is_complex',\n",
              " 'is_distributed',\n",
              " 'is_floating_point',\n",
              " 'is_grad_enabled',\n",
              " 'is_nonzero',\n",
              " 'is_same_size',\n",
              " 'is_signed',\n",
              " 'is_storage',\n",
              " 'is_tensor',\n",
              " 'is_vulkan_available',\n",
              " 'isclose',\n",
              " 'isfinite',\n",
              " 'isinf',\n",
              " 'isnan',\n",
              " 'istft',\n",
              " 'jit',\n",
              " 'kl_div',\n",
              " 'kthvalue',\n",
              " 'layer_norm',\n",
              " 'layout',\n",
              " 'le',\n",
              " 'legacy_contiguous_format',\n",
              " 'lerp',\n",
              " 'lgamma',\n",
              " 'linspace',\n",
              " 'load',\n",
              " 'lobpcg',\n",
              " 'log',\n",
              " 'log10',\n",
              " 'log10_',\n",
              " 'log1p',\n",
              " 'log1p_',\n",
              " 'log2',\n",
              " 'log2_',\n",
              " 'log_',\n",
              " 'log_softmax',\n",
              " 'logaddexp',\n",
              " 'logaddexp2',\n",
              " 'logcumsumexp',\n",
              " 'logdet',\n",
              " 'logical_and',\n",
              " 'logical_not',\n",
              " 'logical_or',\n",
              " 'logical_xor',\n",
              " 'logspace',\n",
              " 'logsumexp',\n",
              " 'long',\n",
              " 'lstm',\n",
              " 'lstm_cell',\n",
              " 'lstsq',\n",
              " 'lt',\n",
              " 'lu',\n",
              " 'lu_solve',\n",
              " 'lu_unpack',\n",
              " 'manual_seed',\n",
              " 'margin_ranking_loss',\n",
              " 'masked_fill',\n",
              " 'masked_scatter',\n",
              " 'masked_select',\n",
              " 'matmul',\n",
              " 'matrix_power',\n",
              " 'matrix_rank',\n",
              " 'max',\n",
              " 'max_pool1d',\n",
              " 'max_pool1d_with_indices',\n",
              " 'max_pool2d',\n",
              " 'max_pool3d',\n",
              " 'mean',\n",
              " 'median',\n",
              " 'memory_format',\n",
              " 'merge_type_from_type_comment',\n",
              " 'meshgrid',\n",
              " 'min',\n",
              " 'miopen_batch_norm',\n",
              " 'miopen_convolution',\n",
              " 'miopen_convolution_transpose',\n",
              " 'miopen_depthwise_convolution',\n",
              " 'miopen_rnn',\n",
              " 'mkldnn_adaptive_avg_pool2d',\n",
              " 'mkldnn_convolution',\n",
              " 'mkldnn_convolution_backward_weights',\n",
              " 'mkldnn_max_pool2d',\n",
              " 'mm',\n",
              " 'mode',\n",
              " 'mul',\n",
              " 'multinomial',\n",
              " 'multiprocessing',\n",
              " 'mv',\n",
              " 'mvlgamma',\n",
              " 'name',\n",
              " 'narrow',\n",
              " 'native_batch_norm',\n",
              " 'native_group_norm',\n",
              " 'native_layer_norm',\n",
              " 'native_norm',\n",
              " 'ne',\n",
              " 'neg',\n",
              " 'neg_',\n",
              " 'nn',\n",
              " 'no_grad',\n",
              " 'nonzero',\n",
              " 'norm',\n",
              " 'norm_except_dim',\n",
              " 'normal',\n",
              " 'nuclear_norm',\n",
              " 'numel',\n",
              " 'ones',\n",
              " 'ones_like',\n",
              " 'onnx',\n",
              " 'ops',\n",
              " 'optim',\n",
              " 'orgqr',\n",
              " 'ormqr',\n",
              " 'os',\n",
              " 'pairwise_distance',\n",
              " 'parse_ir',\n",
              " 'parse_schema',\n",
              " 'parse_type_comment',\n",
              " 'pca_lowrank',\n",
              " 'pdist',\n",
              " 'per_channel_affine',\n",
              " 'per_channel_symmetric',\n",
              " 'per_tensor_affine',\n",
              " 'per_tensor_symmetric',\n",
              " 'pinverse',\n",
              " 'pixel_shuffle',\n",
              " 'platform',\n",
              " 'poisson',\n",
              " 'poisson_nll_loss',\n",
              " 'polygamma',\n",
              " 'pow',\n",
              " 'prelu',\n",
              " 'prepare_multiprocessing_environment',\n",
              " 'preserve_format',\n",
              " 'prod',\n",
              " 'promote_types',\n",
              " 'q_per_channel_axis',\n",
              " 'q_per_channel_scales',\n",
              " 'q_per_channel_zero_points',\n",
              " 'q_scale',\n",
              " 'q_zero_point',\n",
              " 'qint32',\n",
              " 'qint8',\n",
              " 'qr',\n",
              " 'qscheme',\n",
              " 'quantization',\n",
              " 'quantize_per_channel',\n",
              " 'quantize_per_tensor',\n",
              " 'quantized_batch_norm',\n",
              " 'quantized_gru',\n",
              " 'quantized_gru_cell',\n",
              " 'quantized_lstm',\n",
              " 'quantized_lstm_cell',\n",
              " 'quantized_max_pool2d',\n",
              " 'quantized_rnn_relu_cell',\n",
              " 'quantized_rnn_tanh_cell',\n",
              " 'quasirandom',\n",
              " 'quint8',\n",
              " 'rad2deg',\n",
              " 'rad2deg_',\n",
              " 'rand',\n",
              " 'rand_like',\n",
              " 'randint',\n",
              " 'randint_like',\n",
              " 'randn',\n",
              " 'randn_like',\n",
              " 'random',\n",
              " 'randperm',\n",
              " 'range',\n",
              " 'real',\n",
              " 'reciprocal',\n",
              " 'reciprocal_',\n",
              " 'relu',\n",
              " 'relu_',\n",
              " 'remainder',\n",
              " 'renorm',\n",
              " 'repeat_interleave',\n",
              " 'reshape',\n",
              " 'resize_as_',\n",
              " 'result_type',\n",
              " 'rfft',\n",
              " 'rnn_relu',\n",
              " 'rnn_relu_cell',\n",
              " 'rnn_tanh',\n",
              " 'rnn_tanh_cell',\n",
              " 'roll',\n",
              " 'rot90',\n",
              " 'round',\n",
              " 'round_',\n",
              " 'rrelu',\n",
              " 'rrelu_',\n",
              " 'rsqrt',\n",
              " 'rsqrt_',\n",
              " 'rsub',\n",
              " 'saddmm',\n",
              " 'save',\n",
              " 'scalar_tensor',\n",
              " 'scatter',\n",
              " 'scatter_add',\n",
              " 'searchsorted',\n",
              " 'seed',\n",
              " 'select',\n",
              " 'selu',\n",
              " 'selu_',\n",
              " 'serialization',\n",
              " 'set_anomaly_enabled',\n",
              " 'set_autocast_enabled',\n",
              " 'set_default_dtype',\n",
              " 'set_default_tensor_type',\n",
              " 'set_flush_denormal',\n",
              " 'set_grad_enabled',\n",
              " 'set_num_interop_threads',\n",
              " 'set_num_threads',\n",
              " 'set_printoptions',\n",
              " 'set_rng_state',\n",
              " 'short',\n",
              " 'sigmoid',\n",
              " 'sigmoid_',\n",
              " 'sign',\n",
              " 'sin',\n",
              " 'sin_',\n",
              " 'sinh',\n",
              " 'sinh_',\n",
              " 'slogdet',\n",
              " 'smm',\n",
              " 'softmax',\n",
              " 'solve',\n",
              " 'sort',\n",
              " 'sparse',\n",
              " 'sparse_coo',\n",
              " 'sparse_coo_tensor',\n",
              " 'split',\n",
              " 'split_with_sizes',\n",
              " 'spmm',\n",
              " 'sqrt',\n",
              " 'sqrt_',\n",
              " 'square',\n",
              " 'square_',\n",
              " 'squeeze',\n",
              " 'sspaddmm',\n",
              " 'stack',\n",
              " 'std',\n",
              " 'std_mean',\n",
              " 'stft',\n",
              " 'storage',\n",
              " 'strided',\n",
              " 'sub',\n",
              " 'sum',\n",
              " 'svd',\n",
              " 'svd_lowrank',\n",
              " 'symeig',\n",
              " 'sys',\n",
              " 't',\n",
              " 'take',\n",
              " 'tan',\n",
              " 'tan_',\n",
              " 'tanh',\n",
              " 'tanh_',\n",
              " 'tensor',\n",
              " 'tensordot',\n",
              " 'testing',\n",
              " 'threshold',\n",
              " 'threshold_',\n",
              " 'topk',\n",
              " 'torch',\n",
              " 'trace',\n",
              " 'transpose',\n",
              " 'trapz',\n",
              " 'triangular_solve',\n",
              " 'tril',\n",
              " 'tril_indices',\n",
              " 'triplet_margin_loss',\n",
              " 'triu',\n",
              " 'triu_indices',\n",
              " 'true_divide',\n",
              " 'trunc',\n",
              " 'trunc_',\n",
              " 'typename',\n",
              " 'types',\n",
              " 'uint8',\n",
              " 'unbind',\n",
              " 'unique',\n",
              " 'unique_consecutive',\n",
              " 'unsqueeze',\n",
              " 'utils',\n",
              " 'vander',\n",
              " 'var',\n",
              " 'var_mean',\n",
              " 'version',\n",
              " 'view_as_complex',\n",
              " 'view_as_real',\n",
              " 'wait',\n",
              " 'where',\n",
              " 'zero_',\n",
              " 'zeros',\n",
              " 'zeros_like']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JPbw7_TOAMU"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>An uninitialized matrix is declared,\n",
        "    but does not contain definite known\n",
        "    values before it is used. When an\n",
        "    uninitialized matrix is created,\n",
        "    whatever values were in the allocated\n",
        "    memory at the time will appear as the initial values.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97r0c2qJOAMV"
      },
      "source": [
        "Construct a 5x3 matrix, uninitialized:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmR8og-oOAMV",
        "outputId": "a8fa8d37-d8f0-4070-db6d-75dc707ce1eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[8.2919e-36, 0.0000e+00, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 0.0000e+00],\n",
            "        [4.4721e+21, 1.5956e+25, 4.7399e+16],\n",
            "        [9.3233e-09, 8.0221e+17, 5.7453e-44],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crNqz61MBmEg",
        "outputId": "2aab4509-fc03-43f9-9ce9-c9d602fc43c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dir(x)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T',\n",
              " '__abs__',\n",
              " '__add__',\n",
              " '__and__',\n",
              " '__array__',\n",
              " '__array_priority__',\n",
              " '__array_wrap__',\n",
              " '__bool__',\n",
              " '__class__',\n",
              " '__contains__',\n",
              " '__deepcopy__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__div__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__float__',\n",
              " '__floordiv__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__iadd__',\n",
              " '__iand__',\n",
              " '__idiv__',\n",
              " '__ifloordiv__',\n",
              " '__ilshift__',\n",
              " '__imul__',\n",
              " '__index__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__int__',\n",
              " '__invert__',\n",
              " '__ior__',\n",
              " '__ipow__',\n",
              " '__irshift__',\n",
              " '__isub__',\n",
              " '__iter__',\n",
              " '__itruediv__',\n",
              " '__ixor__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__long__',\n",
              " '__lshift__',\n",
              " '__lt__',\n",
              " '__matmul__',\n",
              " '__mod__',\n",
              " '__module__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__neg__',\n",
              " '__new__',\n",
              " '__nonzero__',\n",
              " '__or__',\n",
              " '__pow__',\n",
              " '__radd__',\n",
              " '__rdiv__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__rfloordiv__',\n",
              " '__rmul__',\n",
              " '__rpow__',\n",
              " '__rshift__',\n",
              " '__rsub__',\n",
              " '__rtruediv__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__sub__',\n",
              " '__subclasshook__',\n",
              " '__truediv__',\n",
              " '__weakref__',\n",
              " '__xor__',\n",
              " '_backward_hooks',\n",
              " '_base',\n",
              " '_cdata',\n",
              " '_coalesced_',\n",
              " '_dimI',\n",
              " '_dimV',\n",
              " '_grad',\n",
              " '_grad_fn',\n",
              " '_indices',\n",
              " '_is_view',\n",
              " '_make_subclass',\n",
              " '_nnz',\n",
              " '_update_names',\n",
              " '_values',\n",
              " '_version',\n",
              " 'abs',\n",
              " 'abs_',\n",
              " 'absolute',\n",
              " 'absolute_',\n",
              " 'acos',\n",
              " 'acos_',\n",
              " 'acosh',\n",
              " 'acosh_',\n",
              " 'add',\n",
              " 'add_',\n",
              " 'addbmm',\n",
              " 'addbmm_',\n",
              " 'addcdiv',\n",
              " 'addcdiv_',\n",
              " 'addcmul',\n",
              " 'addcmul_',\n",
              " 'addmm',\n",
              " 'addmm_',\n",
              " 'addmv',\n",
              " 'addmv_',\n",
              " 'addr',\n",
              " 'addr_',\n",
              " 'align_as',\n",
              " 'align_to',\n",
              " 'all',\n",
              " 'allclose',\n",
              " 'angle',\n",
              " 'any',\n",
              " 'apply_',\n",
              " 'argmax',\n",
              " 'argmin',\n",
              " 'argsort',\n",
              " 'as_strided',\n",
              " 'as_strided_',\n",
              " 'as_subclass',\n",
              " 'asin',\n",
              " 'asin_',\n",
              " 'asinh',\n",
              " 'asinh_',\n",
              " 'atan',\n",
              " 'atan2',\n",
              " 'atan2_',\n",
              " 'atan_',\n",
              " 'atanh',\n",
              " 'atanh_',\n",
              " 'backward',\n",
              " 'baddbmm',\n",
              " 'baddbmm_',\n",
              " 'bernoulli',\n",
              " 'bernoulli_',\n",
              " 'bfloat16',\n",
              " 'bincount',\n",
              " 'bitwise_and',\n",
              " 'bitwise_and_',\n",
              " 'bitwise_not',\n",
              " 'bitwise_not_',\n",
              " 'bitwise_or',\n",
              " 'bitwise_or_',\n",
              " 'bitwise_xor',\n",
              " 'bitwise_xor_',\n",
              " 'bmm',\n",
              " 'bool',\n",
              " 'byte',\n",
              " 'cauchy_',\n",
              " 'ceil',\n",
              " 'ceil_',\n",
              " 'char',\n",
              " 'cholesky',\n",
              " 'cholesky_inverse',\n",
              " 'cholesky_solve',\n",
              " 'chunk',\n",
              " 'clamp',\n",
              " 'clamp_',\n",
              " 'clamp_max',\n",
              " 'clamp_max_',\n",
              " 'clamp_min',\n",
              " 'clamp_min_',\n",
              " 'clone',\n",
              " 'coalesce',\n",
              " 'conj',\n",
              " 'contiguous',\n",
              " 'copy_',\n",
              " 'cos',\n",
              " 'cos_',\n",
              " 'cosh',\n",
              " 'cosh_',\n",
              " 'cpu',\n",
              " 'cross',\n",
              " 'cuda',\n",
              " 'cummax',\n",
              " 'cummin',\n",
              " 'cumprod',\n",
              " 'cumsum',\n",
              " 'data',\n",
              " 'data_ptr',\n",
              " 'deg2rad',\n",
              " 'deg2rad_',\n",
              " 'dense_dim',\n",
              " 'dequantize',\n",
              " 'det',\n",
              " 'detach',\n",
              " 'detach_',\n",
              " 'device',\n",
              " 'diag',\n",
              " 'diag_embed',\n",
              " 'diagflat',\n",
              " 'diagonal',\n",
              " 'digamma',\n",
              " 'digamma_',\n",
              " 'dim',\n",
              " 'dist',\n",
              " 'div',\n",
              " 'div_',\n",
              " 'dot',\n",
              " 'double',\n",
              " 'dtype',\n",
              " 'eig',\n",
              " 'element_size',\n",
              " 'eq',\n",
              " 'eq_',\n",
              " 'equal',\n",
              " 'erf',\n",
              " 'erf_',\n",
              " 'erfc',\n",
              " 'erfc_',\n",
              " 'erfinv',\n",
              " 'erfinv_',\n",
              " 'exp',\n",
              " 'exp_',\n",
              " 'expand',\n",
              " 'expand_as',\n",
              " 'expm1',\n",
              " 'expm1_',\n",
              " 'exponential_',\n",
              " 'fft',\n",
              " 'fill_',\n",
              " 'fill_diagonal_',\n",
              " 'flatten',\n",
              " 'flip',\n",
              " 'fliplr',\n",
              " 'flipud',\n",
              " 'float',\n",
              " 'floor',\n",
              " 'floor_',\n",
              " 'floor_divide',\n",
              " 'floor_divide_',\n",
              " 'fmod',\n",
              " 'fmod_',\n",
              " 'frac',\n",
              " 'frac_',\n",
              " 'gather',\n",
              " 'ge',\n",
              " 'ge_',\n",
              " 'geometric_',\n",
              " 'geqrf',\n",
              " 'ger',\n",
              " 'get_device',\n",
              " 'grad',\n",
              " 'grad_fn',\n",
              " 'gt',\n",
              " 'gt_',\n",
              " 'half',\n",
              " 'hardshrink',\n",
              " 'has_names',\n",
              " 'histc',\n",
              " 'ifft',\n",
              " 'imag',\n",
              " 'index_add',\n",
              " 'index_add_',\n",
              " 'index_copy',\n",
              " 'index_copy_',\n",
              " 'index_fill',\n",
              " 'index_fill_',\n",
              " 'index_put',\n",
              " 'index_put_',\n",
              " 'index_select',\n",
              " 'indices',\n",
              " 'int',\n",
              " 'int_repr',\n",
              " 'inverse',\n",
              " 'irfft',\n",
              " 'is_coalesced',\n",
              " 'is_complex',\n",
              " 'is_contiguous',\n",
              " 'is_cuda',\n",
              " 'is_distributed',\n",
              " 'is_floating_point',\n",
              " 'is_leaf',\n",
              " 'is_meta',\n",
              " 'is_mkldnn',\n",
              " 'is_nonzero',\n",
              " 'is_pinned',\n",
              " 'is_quantized',\n",
              " 'is_same_size',\n",
              " 'is_set_to',\n",
              " 'is_shared',\n",
              " 'is_signed',\n",
              " 'is_sparse',\n",
              " 'isclose',\n",
              " 'isfinite',\n",
              " 'isinf',\n",
              " 'isnan',\n",
              " 'istft',\n",
              " 'item',\n",
              " 'kthvalue',\n",
              " 'layout',\n",
              " 'le',\n",
              " 'le_',\n",
              " 'lerp',\n",
              " 'lerp_',\n",
              " 'lgamma',\n",
              " 'lgamma_',\n",
              " 'log',\n",
              " 'log10',\n",
              " 'log10_',\n",
              " 'log1p',\n",
              " 'log1p_',\n",
              " 'log2',\n",
              " 'log2_',\n",
              " 'log_',\n",
              " 'log_normal_',\n",
              " 'log_softmax',\n",
              " 'logaddexp',\n",
              " 'logaddexp2',\n",
              " 'logcumsumexp',\n",
              " 'logdet',\n",
              " 'logical_and',\n",
              " 'logical_and_',\n",
              " 'logical_not',\n",
              " 'logical_not_',\n",
              " 'logical_or',\n",
              " 'logical_or_',\n",
              " 'logical_xor',\n",
              " 'logical_xor_',\n",
              " 'logsumexp',\n",
              " 'long',\n",
              " 'lstsq',\n",
              " 'lt',\n",
              " 'lt_',\n",
              " 'lu',\n",
              " 'lu_solve',\n",
              " 'map2_',\n",
              " 'map_',\n",
              " 'masked_fill',\n",
              " 'masked_fill_',\n",
              " 'masked_scatter',\n",
              " 'masked_scatter_',\n",
              " 'masked_select',\n",
              " 'matmul',\n",
              " 'matrix_power',\n",
              " 'max',\n",
              " 'mean',\n",
              " 'median',\n",
              " 'min',\n",
              " 'mm',\n",
              " 'mode',\n",
              " 'mul',\n",
              " 'mul_',\n",
              " 'multinomial',\n",
              " 'mv',\n",
              " 'mvlgamma',\n",
              " 'mvlgamma_',\n",
              " 'name',\n",
              " 'names',\n",
              " 'narrow',\n",
              " 'narrow_copy',\n",
              " 'ndim',\n",
              " 'ndimension',\n",
              " 'ne',\n",
              " 'ne_',\n",
              " 'neg',\n",
              " 'neg_',\n",
              " 'nelement',\n",
              " 'new',\n",
              " 'new_empty',\n",
              " 'new_full',\n",
              " 'new_ones',\n",
              " 'new_tensor',\n",
              " 'new_zeros',\n",
              " 'nonzero',\n",
              " 'norm',\n",
              " 'normal_',\n",
              " 'numel',\n",
              " 'numpy',\n",
              " 'orgqr',\n",
              " 'ormqr',\n",
              " 'output_nr',\n",
              " 'permute',\n",
              " 'pin_memory',\n",
              " 'pinverse',\n",
              " 'polygamma',\n",
              " 'polygamma_',\n",
              " 'pow',\n",
              " 'pow_',\n",
              " 'prelu',\n",
              " 'prod',\n",
              " 'put_',\n",
              " 'q_per_channel_axis',\n",
              " 'q_per_channel_scales',\n",
              " 'q_per_channel_zero_points',\n",
              " 'q_scale',\n",
              " 'q_zero_point',\n",
              " 'qr',\n",
              " 'qscheme',\n",
              " 'rad2deg',\n",
              " 'rad2deg_',\n",
              " 'random_',\n",
              " 'real',\n",
              " 'reciprocal',\n",
              " 'reciprocal_',\n",
              " 'record_stream',\n",
              " 'refine_names',\n",
              " 'register_hook',\n",
              " 'reinforce',\n",
              " 'relu',\n",
              " 'relu_',\n",
              " 'remainder',\n",
              " 'remainder_',\n",
              " 'rename',\n",
              " 'rename_',\n",
              " 'renorm',\n",
              " 'renorm_',\n",
              " 'repeat',\n",
              " 'repeat_interleave',\n",
              " 'requires_grad',\n",
              " 'requires_grad_',\n",
              " 'reshape',\n",
              " 'reshape_as',\n",
              " 'resize',\n",
              " 'resize_',\n",
              " 'resize_as',\n",
              " 'resize_as_',\n",
              " 'retain_grad',\n",
              " 'rfft',\n",
              " 'roll',\n",
              " 'rot90',\n",
              " 'round',\n",
              " 'round_',\n",
              " 'rsqrt',\n",
              " 'rsqrt_',\n",
              " 'scatter',\n",
              " 'scatter_',\n",
              " 'scatter_add',\n",
              " 'scatter_add_',\n",
              " 'select',\n",
              " 'set_',\n",
              " 'shape',\n",
              " 'share_memory_',\n",
              " 'short',\n",
              " 'sigmoid',\n",
              " 'sigmoid_',\n",
              " 'sign',\n",
              " 'sign_',\n",
              " 'sin',\n",
              " 'sin_',\n",
              " 'sinh',\n",
              " 'sinh_',\n",
              " 'size',\n",
              " 'slogdet',\n",
              " 'smm',\n",
              " 'softmax',\n",
              " 'solve',\n",
              " 'sort',\n",
              " 'sparse_dim',\n",
              " 'sparse_mask',\n",
              " 'sparse_resize_',\n",
              " 'sparse_resize_and_clear_',\n",
              " 'split',\n",
              " 'split_with_sizes',\n",
              " 'sqrt',\n",
              " 'sqrt_',\n",
              " 'square',\n",
              " 'square_',\n",
              " 'squeeze',\n",
              " 'squeeze_',\n",
              " 'sspaddmm',\n",
              " 'std',\n",
              " 'stft',\n",
              " 'storage',\n",
              " 'storage_offset',\n",
              " 'storage_type',\n",
              " 'stride',\n",
              " 'sub',\n",
              " 'sub_',\n",
              " 'sum',\n",
              " 'sum_to_size',\n",
              " 'svd',\n",
              " 'symeig',\n",
              " 't',\n",
              " 't_',\n",
              " 'take',\n",
              " 'tan',\n",
              " 'tan_',\n",
              " 'tanh',\n",
              " 'tanh_',\n",
              " 'to',\n",
              " 'to_dense',\n",
              " 'to_mkldnn',\n",
              " 'to_sparse',\n",
              " 'tolist',\n",
              " 'topk',\n",
              " 'trace',\n",
              " 'transpose',\n",
              " 'transpose_',\n",
              " 'triangular_solve',\n",
              " 'tril',\n",
              " 'tril_',\n",
              " 'triu',\n",
              " 'triu_',\n",
              " 'true_divide',\n",
              " 'true_divide_',\n",
              " 'trunc',\n",
              " 'trunc_',\n",
              " 'type',\n",
              " 'type_as',\n",
              " 'unbind',\n",
              " 'unflatten',\n",
              " 'unfold',\n",
              " 'uniform_',\n",
              " 'unique',\n",
              " 'unique_consecutive',\n",
              " 'unsqueeze',\n",
              " 'unsqueeze_',\n",
              " 'values',\n",
              " 'var',\n",
              " 'view',\n",
              " 'view_as',\n",
              " 'where',\n",
              " 'zero_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB2AubHYOAMX"
      },
      "source": [
        "Construct a randomly initialized matrix:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEy3IwC7OAMX",
        "outputId": "bddedd25-95f8-4fda-f35a-c1e806ae4df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2709, 0.4418, 0.1935],\n",
            "        [0.6829, 0.6547, 0.3868],\n",
            "        [0.6922, 0.6616, 0.8053],\n",
            "        [0.8367, 0.3307, 0.9885],\n",
            "        [0.4422, 0.4828, 0.0281]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ9eNsupOAMZ"
      },
      "source": [
        "Construct a matrix filled zeros and of dtype long:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz5V1rpuOAMZ",
        "outputId": "1e547907-82ec-4ab3-cafa-f3914a5f6817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynoJl7F7OAMb"
      },
      "source": [
        "Construct a tensor directly from data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9BACwYLOAMb",
        "outputId": "2f9c6aa7-3219-48ef-cc37-6142150b31d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsPpqToOOAMf"
      },
      "source": [
        "or create a tensor based on an existing tensor. These methods\n",
        "will reuse properties of the input tensor, e.g. dtype, unless\n",
        "new values are provided by user\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT3C5E8iOAMf",
        "outputId": "bc2d171a-e230-423e-e6ee-5fe133574482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)                                      # result has the same size"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-0.1473, -0.7373,  0.3726],\n",
            "        [-0.4371, -1.1652, -1.6916],\n",
            "        [-1.0850,  0.5019,  0.3709],\n",
            "        [-0.7303, -2.8850,  0.4194],\n",
            "        [-0.3108,  1.0556,  1.0694]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87RpMiNWOAMg"
      },
      "source": [
        "Get its size:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77PwuZGnOAMh",
        "outputId": "c102abd0-5b58-44e7-8433-7df96bd46d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdKwlq8IOAMi"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n",
        "\n",
        "Operations\n",
        "^^^^^^^^^^\n",
        "There are multiple syntaxes for operations. In the following\n",
        "example, we will take a look at the addition operation.\n",
        "\n",
        "Addition: syntax 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciJhIy8SOAMj",
        "outputId": "7ce60cda-ab81-4491-a638-56bd36098843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2540, -0.5598,  1.3320],\n",
            "        [-0.3694, -1.0549, -1.2086],\n",
            "        [-0.8553,  1.1808,  0.6785],\n",
            "        [-0.4651, -2.3567,  1.2814],\n",
            "        [-0.1625,  1.7904,  1.8906]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS2X9YDlOAMk"
      },
      "source": [
        "Addition: syntax 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCCqgCkHOAMk",
        "outputId": "3e95cf78-2ef6-4a46-a2ef-79bf715bd871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(torch.add(x, y))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2540, -0.5598,  1.3320],\n",
            "        [-0.3694, -1.0549, -1.2086],\n",
            "        [-0.8553,  1.1808,  0.6785],\n",
            "        [-0.4651, -2.3567,  1.2814],\n",
            "        [-0.1625,  1.7904,  1.8906]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtCmuEyLOAMm"
      },
      "source": [
        "Addition: providing an output tensor as argument\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc3CZcpEOAMm",
        "outputId": "cad1cade-ab42-4f38-c87f-b24a23509974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2540, -0.5598,  1.3320],\n",
            "        [-0.3694, -1.0549, -1.2086],\n",
            "        [-0.8553,  1.1808,  0.6785],\n",
            "        [-0.4651, -2.3567,  1.2814],\n",
            "        [-0.1625,  1.7904,  1.8906]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT6mJVkrOAMo"
      },
      "source": [
        "Addition: in-place\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVg_dA9HOAMo",
        "outputId": "b8c1de91-3d94-4a08-a264-2c581cb83408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# adds x to y\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2540, -0.5598,  1.3320],\n",
            "        [-0.3694, -1.0549, -1.2086],\n",
            "        [-0.8553,  1.1808,  0.6785],\n",
            "        [-0.4651, -2.3567,  1.2814],\n",
            "        [-0.1625,  1.7904,  1.8906]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU2-ZC-NOAMq"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
        "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n",
        "\n",
        "You can use standard NumPy-like indexing with all bells and whistles!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m6244MPOAMq",
        "outputId": "6e1b3d70-42f4-4e11-e5e2-fb1dde3c404e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x[:, 1])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.7373, -1.1652,  0.5019, -2.8850,  1.0556])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFvrj3EPOAMs"
      },
      "source": [
        "Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VliG_-fmOAMs",
        "outputId": "5f2a100e-df8d-42a4-8fe0-659835ef1773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVyhh2yMOAMu"
      },
      "source": [
        "If you have a one element tensor, use ``.item()`` to get the value as a\n",
        "Python number\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG4AbZzEOAMu",
        "outputId": "750b65ad-a9b2-4ebf-afc1-ff1f7455d6b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-2.4998])\n",
            "-2.499812126159668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMa8SckgOAMw"
      },
      "source": [
        "**Read later:**\n",
        "\n",
        "\n",
        "  100+ Tensor operations, including transposing, indexing, slicing,\n",
        "  mathematical operations, linear algebra, random numbers, etc.,\n",
        "  are described\n",
        "  `here <https://pytorch.org/docs/torch>`_.\n",
        "\n",
        "NumPy Bridge\n",
        "------------\n",
        "\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
        "\n",
        "The Torch Tensor and NumPy array will share their underlying memory\n",
        "locations (if the Torch Tensor is on CPU), and changing one will change\n",
        "the other.\n",
        "\n",
        "Converting a Torch Tensor to a NumPy Array\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iamrtMPVOAMw",
        "outputId": "a6c2dfa6-07b4-486d-fecd-5d1d09b0092a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL9ou7BYOAMy",
        "outputId": "4b7cb5de-a91a-48bd-b1c6-ee9efc99d4f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzE055pgOAMz"
      },
      "source": [
        "See how the numpy array changed in value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEX8S0l0OAMz",
        "outputId": "ee9458ce-ecc8-4395-fd82-ba8de7ef4e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nY6cr9fOAM1"
      },
      "source": [
        "Converting NumPy Array to Torch Tensor\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "See how changing the np array changed the Torch Tensor automatically\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUa6FyOTOAM1",
        "outputId": "375e21dd-dcb5-46e7-bd7a-376f537a7300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49dcj7E1OAM3"
      },
      "source": [
        "All the Tensors on the CPU except a CharTensor support converting to\n",
        "NumPy and back.\n",
        "\n",
        "CUDA Tensors\n",
        "------------\n",
        "\n",
        "Tensors can be moved onto any device using the ``.to`` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBOOQ3j0OAM3"
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2cQfI0IBtUL"
      },
      "source": [
        "# Tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FHhWrYbBu0L",
        "outputId": "02e304d0-da08-4fa2-903a-05bdfaf14e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0bec52d5a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qM6fEajB1sv",
        "outputId": "8f213296-1728-48be-fda4-f9ecdf456342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# torch.tensor(data) creates a torch.Tensor object with the given data.\n",
        "\n",
        "V_data = [1., 2., 3., 4., 5., 6., 7., 8., 9.]\n",
        "\n",
        "V = torch.tensor(V_data)\n",
        "\n",
        "print(V)\n",
        "\n",
        "# Creates a matrix M\n",
        "\n",
        "M_data = [[1., 2., 3.], [4., 5., 6]]\n",
        "\n",
        "M = torch.tensor(M_data)\n",
        "\n",
        "print(M)\n",
        "\n",
        "print(type(M))\n"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H83Vs1jB5gX",
        "outputId": "2feb7012-e3e5-45ae-e34e-e092569887a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Create a 3D tensor of size 2x2x2\n",
        "\n",
        "T_data = [[[1., 2.], [3., 4.]],\n",
        "          [[5., 6.], [7., 8.]]]\n",
        "\n",
        "T = torch.tensor(T_data)\n",
        "\n",
        "print(T)\n",
        "\n",
        "dir(T)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1., 2.],\n",
            "         [3., 4.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T',\n",
              " '__abs__',\n",
              " '__add__',\n",
              " '__and__',\n",
              " '__array__',\n",
              " '__array_priority__',\n",
              " '__array_wrap__',\n",
              " '__bool__',\n",
              " '__class__',\n",
              " '__contains__',\n",
              " '__deepcopy__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__div__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__float__',\n",
              " '__floordiv__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__iadd__',\n",
              " '__iand__',\n",
              " '__idiv__',\n",
              " '__ifloordiv__',\n",
              " '__ilshift__',\n",
              " '__imul__',\n",
              " '__index__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__int__',\n",
              " '__invert__',\n",
              " '__ior__',\n",
              " '__ipow__',\n",
              " '__irshift__',\n",
              " '__isub__',\n",
              " '__iter__',\n",
              " '__itruediv__',\n",
              " '__ixor__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__long__',\n",
              " '__lshift__',\n",
              " '__lt__',\n",
              " '__matmul__',\n",
              " '__mod__',\n",
              " '__module__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__neg__',\n",
              " '__new__',\n",
              " '__nonzero__',\n",
              " '__or__',\n",
              " '__pow__',\n",
              " '__radd__',\n",
              " '__rdiv__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__rfloordiv__',\n",
              " '__rmul__',\n",
              " '__rpow__',\n",
              " '__rshift__',\n",
              " '__rsub__',\n",
              " '__rtruediv__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__sub__',\n",
              " '__subclasshook__',\n",
              " '__truediv__',\n",
              " '__weakref__',\n",
              " '__xor__',\n",
              " '_backward_hooks',\n",
              " '_base',\n",
              " '_cdata',\n",
              " '_coalesced_',\n",
              " '_dimI',\n",
              " '_dimV',\n",
              " '_grad',\n",
              " '_grad_fn',\n",
              " '_indices',\n",
              " '_is_view',\n",
              " '_make_subclass',\n",
              " '_nnz',\n",
              " '_update_names',\n",
              " '_values',\n",
              " '_version',\n",
              " 'abs',\n",
              " 'abs_',\n",
              " 'absolute',\n",
              " 'absolute_',\n",
              " 'acos',\n",
              " 'acos_',\n",
              " 'acosh',\n",
              " 'acosh_',\n",
              " 'add',\n",
              " 'add_',\n",
              " 'addbmm',\n",
              " 'addbmm_',\n",
              " 'addcdiv',\n",
              " 'addcdiv_',\n",
              " 'addcmul',\n",
              " 'addcmul_',\n",
              " 'addmm',\n",
              " 'addmm_',\n",
              " 'addmv',\n",
              " 'addmv_',\n",
              " 'addr',\n",
              " 'addr_',\n",
              " 'align_as',\n",
              " 'align_to',\n",
              " 'all',\n",
              " 'allclose',\n",
              " 'angle',\n",
              " 'any',\n",
              " 'apply_',\n",
              " 'argmax',\n",
              " 'argmin',\n",
              " 'argsort',\n",
              " 'as_strided',\n",
              " 'as_strided_',\n",
              " 'as_subclass',\n",
              " 'asin',\n",
              " 'asin_',\n",
              " 'asinh',\n",
              " 'asinh_',\n",
              " 'atan',\n",
              " 'atan2',\n",
              " 'atan2_',\n",
              " 'atan_',\n",
              " 'atanh',\n",
              " 'atanh_',\n",
              " 'backward',\n",
              " 'baddbmm',\n",
              " 'baddbmm_',\n",
              " 'bernoulli',\n",
              " 'bernoulli_',\n",
              " 'bfloat16',\n",
              " 'bincount',\n",
              " 'bitwise_and',\n",
              " 'bitwise_and_',\n",
              " 'bitwise_not',\n",
              " 'bitwise_not_',\n",
              " 'bitwise_or',\n",
              " 'bitwise_or_',\n",
              " 'bitwise_xor',\n",
              " 'bitwise_xor_',\n",
              " 'bmm',\n",
              " 'bool',\n",
              " 'byte',\n",
              " 'cauchy_',\n",
              " 'ceil',\n",
              " 'ceil_',\n",
              " 'char',\n",
              " 'cholesky',\n",
              " 'cholesky_inverse',\n",
              " 'cholesky_solve',\n",
              " 'chunk',\n",
              " 'clamp',\n",
              " 'clamp_',\n",
              " 'clamp_max',\n",
              " 'clamp_max_',\n",
              " 'clamp_min',\n",
              " 'clamp_min_',\n",
              " 'clone',\n",
              " 'coalesce',\n",
              " 'conj',\n",
              " 'contiguous',\n",
              " 'copy_',\n",
              " 'cos',\n",
              " 'cos_',\n",
              " 'cosh',\n",
              " 'cosh_',\n",
              " 'cpu',\n",
              " 'cross',\n",
              " 'cuda',\n",
              " 'cummax',\n",
              " 'cummin',\n",
              " 'cumprod',\n",
              " 'cumsum',\n",
              " 'data',\n",
              " 'data_ptr',\n",
              " 'deg2rad',\n",
              " 'deg2rad_',\n",
              " 'dense_dim',\n",
              " 'dequantize',\n",
              " 'det',\n",
              " 'detach',\n",
              " 'detach_',\n",
              " 'device',\n",
              " 'diag',\n",
              " 'diag_embed',\n",
              " 'diagflat',\n",
              " 'diagonal',\n",
              " 'digamma',\n",
              " 'digamma_',\n",
              " 'dim',\n",
              " 'dist',\n",
              " 'div',\n",
              " 'div_',\n",
              " 'dot',\n",
              " 'double',\n",
              " 'dtype',\n",
              " 'eig',\n",
              " 'element_size',\n",
              " 'eq',\n",
              " 'eq_',\n",
              " 'equal',\n",
              " 'erf',\n",
              " 'erf_',\n",
              " 'erfc',\n",
              " 'erfc_',\n",
              " 'erfinv',\n",
              " 'erfinv_',\n",
              " 'exp',\n",
              " 'exp_',\n",
              " 'expand',\n",
              " 'expand_as',\n",
              " 'expm1',\n",
              " 'expm1_',\n",
              " 'exponential_',\n",
              " 'fft',\n",
              " 'fill_',\n",
              " 'fill_diagonal_',\n",
              " 'flatten',\n",
              " 'flip',\n",
              " 'fliplr',\n",
              " 'flipud',\n",
              " 'float',\n",
              " 'floor',\n",
              " 'floor_',\n",
              " 'floor_divide',\n",
              " 'floor_divide_',\n",
              " 'fmod',\n",
              " 'fmod_',\n",
              " 'frac',\n",
              " 'frac_',\n",
              " 'gather',\n",
              " 'ge',\n",
              " 'ge_',\n",
              " 'geometric_',\n",
              " 'geqrf',\n",
              " 'ger',\n",
              " 'get_device',\n",
              " 'grad',\n",
              " 'grad_fn',\n",
              " 'gt',\n",
              " 'gt_',\n",
              " 'half',\n",
              " 'hardshrink',\n",
              " 'has_names',\n",
              " 'histc',\n",
              " 'ifft',\n",
              " 'imag',\n",
              " 'index_add',\n",
              " 'index_add_',\n",
              " 'index_copy',\n",
              " 'index_copy_',\n",
              " 'index_fill',\n",
              " 'index_fill_',\n",
              " 'index_put',\n",
              " 'index_put_',\n",
              " 'index_select',\n",
              " 'indices',\n",
              " 'int',\n",
              " 'int_repr',\n",
              " 'inverse',\n",
              " 'irfft',\n",
              " 'is_coalesced',\n",
              " 'is_complex',\n",
              " 'is_contiguous',\n",
              " 'is_cuda',\n",
              " 'is_distributed',\n",
              " 'is_floating_point',\n",
              " 'is_leaf',\n",
              " 'is_meta',\n",
              " 'is_mkldnn',\n",
              " 'is_nonzero',\n",
              " 'is_pinned',\n",
              " 'is_quantized',\n",
              " 'is_same_size',\n",
              " 'is_set_to',\n",
              " 'is_shared',\n",
              " 'is_signed',\n",
              " 'is_sparse',\n",
              " 'isclose',\n",
              " 'isfinite',\n",
              " 'isinf',\n",
              " 'isnan',\n",
              " 'istft',\n",
              " 'item',\n",
              " 'kthvalue',\n",
              " 'layout',\n",
              " 'le',\n",
              " 'le_',\n",
              " 'lerp',\n",
              " 'lerp_',\n",
              " 'lgamma',\n",
              " 'lgamma_',\n",
              " 'log',\n",
              " 'log10',\n",
              " 'log10_',\n",
              " 'log1p',\n",
              " 'log1p_',\n",
              " 'log2',\n",
              " 'log2_',\n",
              " 'log_',\n",
              " 'log_normal_',\n",
              " 'log_softmax',\n",
              " 'logaddexp',\n",
              " 'logaddexp2',\n",
              " 'logcumsumexp',\n",
              " 'logdet',\n",
              " 'logical_and',\n",
              " 'logical_and_',\n",
              " 'logical_not',\n",
              " 'logical_not_',\n",
              " 'logical_or',\n",
              " 'logical_or_',\n",
              " 'logical_xor',\n",
              " 'logical_xor_',\n",
              " 'logsumexp',\n",
              " 'long',\n",
              " 'lstsq',\n",
              " 'lt',\n",
              " 'lt_',\n",
              " 'lu',\n",
              " 'lu_solve',\n",
              " 'map2_',\n",
              " 'map_',\n",
              " 'masked_fill',\n",
              " 'masked_fill_',\n",
              " 'masked_scatter',\n",
              " 'masked_scatter_',\n",
              " 'masked_select',\n",
              " 'matmul',\n",
              " 'matrix_power',\n",
              " 'max',\n",
              " 'mean',\n",
              " 'median',\n",
              " 'min',\n",
              " 'mm',\n",
              " 'mode',\n",
              " 'mul',\n",
              " 'mul_',\n",
              " 'multinomial',\n",
              " 'mv',\n",
              " 'mvlgamma',\n",
              " 'mvlgamma_',\n",
              " 'name',\n",
              " 'names',\n",
              " 'narrow',\n",
              " 'narrow_copy',\n",
              " 'ndim',\n",
              " 'ndimension',\n",
              " 'ne',\n",
              " 'ne_',\n",
              " 'neg',\n",
              " 'neg_',\n",
              " 'nelement',\n",
              " 'new',\n",
              " 'new_empty',\n",
              " 'new_full',\n",
              " 'new_ones',\n",
              " 'new_tensor',\n",
              " 'new_zeros',\n",
              " 'nonzero',\n",
              " 'norm',\n",
              " 'normal_',\n",
              " 'numel',\n",
              " 'numpy',\n",
              " 'orgqr',\n",
              " 'ormqr',\n",
              " 'output_nr',\n",
              " 'permute',\n",
              " 'pin_memory',\n",
              " 'pinverse',\n",
              " 'polygamma',\n",
              " 'polygamma_',\n",
              " 'pow',\n",
              " 'pow_',\n",
              " 'prelu',\n",
              " 'prod',\n",
              " 'put_',\n",
              " 'q_per_channel_axis',\n",
              " 'q_per_channel_scales',\n",
              " 'q_per_channel_zero_points',\n",
              " 'q_scale',\n",
              " 'q_zero_point',\n",
              " 'qr',\n",
              " 'qscheme',\n",
              " 'rad2deg',\n",
              " 'rad2deg_',\n",
              " 'random_',\n",
              " 'real',\n",
              " 'reciprocal',\n",
              " 'reciprocal_',\n",
              " 'record_stream',\n",
              " 'refine_names',\n",
              " 'register_hook',\n",
              " 'reinforce',\n",
              " 'relu',\n",
              " 'relu_',\n",
              " 'remainder',\n",
              " 'remainder_',\n",
              " 'rename',\n",
              " 'rename_',\n",
              " 'renorm',\n",
              " 'renorm_',\n",
              " 'repeat',\n",
              " 'repeat_interleave',\n",
              " 'requires_grad',\n",
              " 'requires_grad_',\n",
              " 'reshape',\n",
              " 'reshape_as',\n",
              " 'resize',\n",
              " 'resize_',\n",
              " 'resize_as',\n",
              " 'resize_as_',\n",
              " 'retain_grad',\n",
              " 'rfft',\n",
              " 'roll',\n",
              " 'rot90',\n",
              " 'round',\n",
              " 'round_',\n",
              " 'rsqrt',\n",
              " 'rsqrt_',\n",
              " 'scatter',\n",
              " 'scatter_',\n",
              " 'scatter_add',\n",
              " 'scatter_add_',\n",
              " 'select',\n",
              " 'set_',\n",
              " 'shape',\n",
              " 'share_memory_',\n",
              " 'short',\n",
              " 'sigmoid',\n",
              " 'sigmoid_',\n",
              " 'sign',\n",
              " 'sign_',\n",
              " 'sin',\n",
              " 'sin_',\n",
              " 'sinh',\n",
              " 'sinh_',\n",
              " 'size',\n",
              " 'slogdet',\n",
              " 'smm',\n",
              " 'softmax',\n",
              " 'solve',\n",
              " 'sort',\n",
              " 'sparse_dim',\n",
              " 'sparse_mask',\n",
              " 'sparse_resize_',\n",
              " 'sparse_resize_and_clear_',\n",
              " 'split',\n",
              " 'split_with_sizes',\n",
              " 'sqrt',\n",
              " 'sqrt_',\n",
              " 'square',\n",
              " 'square_',\n",
              " 'squeeze',\n",
              " 'squeeze_',\n",
              " 'sspaddmm',\n",
              " 'std',\n",
              " 'stft',\n",
              " 'storage',\n",
              " 'storage_offset',\n",
              " 'storage_type',\n",
              " 'stride',\n",
              " 'sub',\n",
              " 'sub_',\n",
              " 'sum',\n",
              " 'sum_to_size',\n",
              " 'svd',\n",
              " 'symeig',\n",
              " 't',\n",
              " 't_',\n",
              " 'take',\n",
              " 'tan',\n",
              " 'tan_',\n",
              " 'tanh',\n",
              " 'tanh_',\n",
              " 'to',\n",
              " 'to_dense',\n",
              " 'to_mkldnn',\n",
              " 'to_sparse',\n",
              " 'tolist',\n",
              " 'topk',\n",
              " 'trace',\n",
              " 'transpose',\n",
              " 'transpose_',\n",
              " 'triangular_solve',\n",
              " 'tril',\n",
              " 'tril_',\n",
              " 'triu',\n",
              " 'triu_',\n",
              " 'true_divide',\n",
              " 'true_divide_',\n",
              " 'trunc',\n",
              " 'trunc_',\n",
              " 'type',\n",
              " 'type_as',\n",
              " 'unbind',\n",
              " 'unflatten',\n",
              " 'unfold',\n",
              " 'uniform_',\n",
              " 'unique',\n",
              " 'unique_consecutive',\n",
              " 'unsqueeze',\n",
              " 'unsqueeze_',\n",
              " 'values',\n",
              " 'var',\n",
              " 'view',\n",
              " 'view_as',\n",
              " 'where',\n",
              " 'zero_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEkPb-6HCWyp",
        "outputId": "deb335a7-aa8b-4191-b398-25488401a820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "T"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2.],\n",
              "         [3., 4.]],\n",
              "\n",
              "        [[5., 6.],\n",
              "         [7., 8.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s40UbZrCLrp",
        "outputId": "d1bd8088-e775-44d3-c325-e356f8a71623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "T.abs()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2.],\n",
              "         [3., 4.]],\n",
              "\n",
              "        [[5., 6.],\n",
              "         [7., 8.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGi_S1sxCfCB",
        "outputId": "bc6e27eb-38ee-47b8-98ae-e633751fc299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "T.add(T)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 2.,  4.],\n",
              "         [ 6.,  8.]],\n",
              "\n",
              "        [[10., 12.],\n",
              "         [14., 16.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4TEYDHjCjAR",
        "outputId": "3726d93d-7457-4233-cbe2-7d83a43fde42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(T)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1., 2.],\n",
            "         [3., 4.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVvYdGKbCoFJ"
      },
      "source": [
        "#  T.allclose?"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OyaqOWJCpUo",
        "outputId": "af2db52f-4e9f-4e35-e464-0bcc9ba9f8c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "T.backward"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Tensor.backward of tensor([[[1., 2.],\n",
              "         [3., 4.]],\n",
              "\n",
              "        [[5., 6.],\n",
              "         [7., 8.]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA31eBmNC2NJ",
        "outputId": "244e2f5d-b084-40e2-8143-cdb8c92d003f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "T.dim()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OObpN6fDIG4",
        "outputId": "bf64d498-7c3c-46ca-c91b-8302f7a864a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Index into V and get a scalar (0 dimensional tensor)\n",
        "print(V[0])\n",
        "# Get a Python number from it\n",
        "print(V[0].item())\n",
        "\n",
        "# Index into M and get a vector\n",
        "print(M[0])\n",
        "\n",
        "# Index into T and get a matrix\n",
        "print(T[0])"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n",
            "1.0\n",
            "tensor([1., 2., 3.])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJXcva-LDMBh",
        "outputId": "805e7b82-5308-4ee2-ffd3-3590c50c9163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([1., 2., 3.])\n",
        "y = torch.tensor([4., 5., 6.])\n",
        "z = x + y\n",
        "print(z)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5., 7., 9.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSq-FrcUDUCQ",
        "outputId": "22ed91f4-11ec-4488-a836-011a75cf59ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# By default, it concatenates along the first axis (concatenates rows)\n",
        "x_1 = torch.randn(2, 5)\n",
        "y_1 = torch.randn(3, 5)\n",
        "z_1 = torch.cat([x_1, y_1])\n",
        "print(z_1)\n",
        "\n",
        "# Concatenate columns:\n",
        "x_2 = torch.randn(2, 3)\n",
        "y_2 = torch.randn(2, 5)\n",
        "# second arg specifies which axis to concat along\n",
        "z_2 = torch.cat([x_2, y_2], 1)\n",
        "print(z_2)\n",
        "\n",
        "# If your tensors are not compatible, torch will complain.  Uncomment to see the error\n",
        "# torch.cat([x_1, x_2])\n"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519],\n",
            "        [-0.1661, -1.5228,  0.3817, -1.0276, -0.5631],\n",
            "        [-0.8923, -0.0583, -0.1955, -0.9656,  0.4224],\n",
            "        [ 0.2673, -0.4212, -0.5107, -1.5727, -0.1232],\n",
            "        [ 3.5870, -1.8313,  1.5987, -1.2770,  0.3255]])\n",
            "tensor([[-0.4791,  1.3790,  2.5286,  0.5423,  0.1103, -2.2590,  0.6067, -0.1383],\n",
            "        [ 0.4107, -0.9880, -0.9081,  0.8310, -0.2477, -0.8029,  0.2366,  0.2857]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRtYFZgvDkdg",
        "outputId": "6ace5ce0-5974-4d65-ea8e-3cc91255860c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "### reshaping tensors:\n",
        "\n",
        "# Use the .view() method to reshape a tensor. This method receives heavy use, \n",
        "# because many neural network components expect their inputs to have a certain shape. \n",
        "# Often you will need to reshape before passing your data to the component.\n",
        "\n",
        "x = torch.randn(2, 3, 4)\n",
        "print(x)\n",
        "\n",
        "\n",
        "print(x.view(2, 12))  # Reshape to 2 rows, 12 columns\n",
        "# Same as above.  If one of the dimensions is -1, its size can be inferred\n",
        "print(x.view(2, -1))\n"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-1.4344, -0.5008,  0.1716, -0.1600],\n",
            "         [-0.5047, -1.4746, -0.3416, -0.3003],\n",
            "         [ 1.2466,  0.5057,  0.9505,  1.2966]],\n",
            "\n",
            "        [[ 0.8738, -0.5603,  1.2858,  0.8168],\n",
            "         [-1.4648, -1.2629,  1.1220,  1.5663],\n",
            "         [ 2.5581, -0.2334, -0.0135,  1.8606]]])\n",
            "tensor([[-1.4344, -0.5008,  0.1716, -0.1600, -0.5047, -1.4746, -0.3416, -0.3003,\n",
            "          1.2466,  0.5057,  0.9505,  1.2966],\n",
            "        [ 0.8738, -0.5603,  1.2858,  0.8168, -1.4648, -1.2629,  1.1220,  1.5663,\n",
            "          2.5581, -0.2334, -0.0135,  1.8606]])\n",
            "tensor([[-1.4344, -0.5008,  0.1716, -0.1600, -0.5047, -1.4746, -0.3416, -0.3003,\n",
            "          1.2466,  0.5057,  0.9505,  1.2966],\n",
            "        [ 0.8738, -0.5603,  1.2858,  0.8168, -1.4648, -1.2629,  1.1220,  1.5663,\n",
            "          2.5581, -0.2334, -0.0135,  1.8606]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFfQQpcyDqVx",
        "outputId": "86ad7b50-ab97-4767-84f3-650ad0a0f58e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "aa = [[1,2,3,4,5,6,7], [8,9,10,11,12,13,14]]\n",
        "TA = torch.tensor(aa)\n",
        "TA"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11, 12, 13, 14]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvQ1fHT_D8Tp",
        "outputId": "d8a98637-9d0a-4ad8-8003-2634826e7925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "TA.view(7,2)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2],\n",
              "        [ 3,  4],\n",
              "        [ 5,  6],\n",
              "        [ 7,  8],\n",
              "        [ 9, 10],\n",
              "        [11, 12],\n",
              "        [13, 14]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcmT91mGE0v6"
      },
      "source": [
        "# ODD:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOJsqCyuE8kM"
      },
      "source": [
        "Computation Graphs and Automatic Differentiation\n",
        "The concept of a computation graph is essential to efficient deep learning programming, because it allows you to not have to write the back propagation gradients yourself. A computation graph is simply a specification of how your data is combined to give you the output. Since the graph totally specifies what parameters were involved with which operations, it contains enough information to compute derivatives. This probably sounds vague, so let’s see what is going on using the fundamental flag requires_grad.\n",
        "\n",
        "First, think from a programmers perspective. What is stored in the torch.Tensor objects we were creating above? Obviously the data and the shape, and maybe a few other things. But when we added two tensors together, we got an output tensor. All this output tensor knows is its data and shape. It has no idea that it was the sum of two other tensors (it could have been read in from a file, it could be the result of some other operation, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEOKqGZ8Ezl6",
        "outputId": "b32bfc47-b0bf-47a6-f881-9df2d661f001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "# Tensor factory methods have a ``requires_grad`` flag\n",
        "x = torch.tensor([1., 2., 3], requires_grad=True)\n",
        "\n",
        "\n",
        "# With requires_grad=True, you can still do all the operations you previously\n",
        "# could\n",
        "y = torch.tensor([4., 5., 6], requires_grad=True)\n",
        "z = x + y\n",
        "\n",
        "print(z)\n",
        "\n",
        "# BUT z knows something extra.\n",
        "print(z.grad_fn)\n",
        "\n",
        "#  If requires_grad=True, the Tensor object keeps track of how it was created. Lets see it in action.\n",
        "\n",
        "\n",
        "# So Tensors know what created them. z knows that it wasn’t read in from a file, it wasn’t the \n",
        "# result of a multiplication or exponential or whatever. And if you keep following z.grad_fn, \n",
        "# you will find yourself at x and y.\n"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5., 7., 9.], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7f0b99ebbf28>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqEK9ydoE5hw",
        "outputId": "4101da56-152d-4a14-9338-614b279eb4d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Lets sum up all the entries in z\n",
        "s = z.sum()\n",
        "print(s)\n",
        "print(s.grad_fn)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(21., grad_fn=<SumBackward0>)\n",
            "<SumBackward0 object at 0x7f0b9967f2e8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DorZ-tjGFN4Y",
        "outputId": "aa0d5d5b-a2a3-48e3-a6ba-c82111ea085e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calling .backward() on any variable will run backprop, starting from it.\n",
        "s.backward()\n",
        "print(x.grad)\n"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXqxcssqFfdl",
        "outputId": "67907604-4793-4fc4-ede9-e19d682b63f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\n",
        "\n",
        "x = torch.randn(2, 2)\n",
        "y = torch.randn(2, 2)\n",
        "\n",
        "\n",
        "# By default, user created Tensors have ``requires_grad=False``\n",
        "print(x.requires_grad, y.requires_grad)\n",
        "\n",
        "\n",
        "z = x + y\n",
        "# So you can't backprop through z\n",
        "print(z.grad_fn)\n",
        "\n",
        "\n",
        "# ``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
        "# flag in-place. The input flag defaults to ``True`` if not given.\n",
        "\n",
        "x = x.requires_grad_()\n",
        "y = y.requires_grad_()\n",
        "\n",
        "\n",
        "# z contains enough information to compute gradients, as we saw above\n",
        "z = x + y\n",
        "print(z.grad_fn)\n",
        "\n",
        "# If any input to an operation has ``requires_grad=True``, so will the output\n",
        "print(z.requires_grad)\n",
        "\n",
        "\n",
        "# Now z has the computation history that relates itself to x and y\n",
        "# Can we just take its values, and **detach** it from its history?\n",
        "new_z = z.detach()\n",
        "\n",
        "\n",
        "# ... does new_z have information to backprop to x and y?\n",
        "# NO!\n",
        "\n",
        "\n",
        "print(new_z.grad_fn)\n",
        "# And how could it? ``z.detach()`` returns a tensor that shares the same storage\n",
        "# as ``z``, but with the computation history forgotten. It doesn't know anything\n",
        "# about how it was computed.\n",
        "# In essence, we have broken the Tensor away from its past history\n"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False False\n",
            "None\n",
            "<AddBackward0 object at 0x7f0b99685160>\n",
            "True\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}